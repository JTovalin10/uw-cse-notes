1. In a multi-threaded system, like Windows or Unix, each thread in a process has individually assigned heaps to avoid scheduling conflicts.
	1. threads share everything except stack, registers, and program counter. they share the heap and this causes race conditions
2. In a multi-threaded system like Windows or Unix each thread is assigned its own runtime stack.
	1. true
3. In a modern Operating System the kernel is generally not aware of traditional user level threads.
	1. true, the kernel is not aware of user level threads, it only sees the kernel threads that those user level threads are mapped to (1 kernel level thread : many user level thread; 1:m). THe user space thread handles everything for user level thread
4. Kernel threads and User-Level threads were added to Operating Systems independent of multi-core computers.
	1. they were introduced before multi-core computers as they are used for concurrency
5. In a modern Operating System, such as Windows or Unix, User-level threads run at a higher priority than kernel threads to boost performance
	1. while they do run faster due to less overhead and less schedule shenagains. The kernel is not aware of user-level threads so they are not factored into scheduling
6. The process is identified with a unique value (PID). And once the process terminates the Operating System only needs to hold onto (i.e., reserve) the PID until the system goes idle before it can freely recycle the value.
	1. we dont wait for the system to idle. the thread exits and the parent ack the termination and when calling wait, it will recycle the PID
7. In a modern operating system each process is assigned no more kernel threads than there are CPU's on the system.
	1. the scheduler can schedule more kernel threads than there are cores. However, if we schedule 10 kernel threads (or user threds) on a 4-core system only 4 of those threads can run at a given time
8. User-level threads were added to the Operating System to speed up multi-core computers.
	1. false, threading was introduced for concurrency--single core machines. Parallelism is multiple tasks executing at the same time on multiple cores
9. The user is responsible for not over running its runtime stack.
	1. user level threads are allocated a fixed sized stack for each thread. They dont get the protection of kernel level stacks hence, if you overflow them the kernel doesnt know and thats on you. **Undefined Behavior**
		1. kernel level thread get guard pages so those will segfault
10. In Windows or Unix, only a parent can terminate its child process.
	1. false, if a user spawns a process they can terminate it with kill or SIGKILL--the command isnt a parent process but has permission to kill it
11. When the kernel reaches the limit of its kernel stack it will extend its stack onto the user's stack.
	1. false, they are seperated so this couldnt even happen. But if they were contigous it still wouldnt happen as kernel has guardrails so it will crash the system
12. For security reasons the Kernel is not allowed to access the user stack.
	1. false, the kernel can access anything. However, it doesnt access the user stack as there may be malicious code. so during a syscall it will getr the info it needs and then swap to its kernel stack to execute the kernel stack
13. In a multi-threaded system, like Windows or Unix, each thread in a process can also access the runtime stack of other threads in the same process.
	1. true, the OS only protects processes from each other not threads within the same process. The stacks are inside the same verituak address so any thread can read ore write memory of another threads stack
14. Disabling and enabling interrupts is a way of implementing spinlocks on a uniprocessor machine.
	1. this works if they are in kernel mode as the only thing that could interrupt it are timer, I/O interrupt, or another preemptive event. So we can disable and enable it so that once you enter a crtiical section you cannot be interrupted
	2. this wonty work on a multiprocessor machine as only that core will disable the interrupt so other cores can still work. this means  that we will still need atomics for mutlicore
15. Condition Variables implemented with MESA semantics have the advantage over Hoare semantics in that they avoid starvation.
	1. both hoare and MESA dont avoid starvation
16. A difference between a spinlock and a semaphore is that the former is implemented with a queue of waiters for the lock.
	1. semaphore uses a queue. spinlock is just a while loop
17. The advantage that Condition Variables have over Reader/Writer locks is that they can be implemented without using spinlocks.
	1. false, sspinlock is the primitive
18. A starvation is when at least two processes are stuck waiting for a resource currently held by the other process.
	1. false, this is a deadlock
19. A difference between a semaphore and a spinlock is that the former yields the processor if it cannot acquire the lock.
	1. true, spinlock has the processor waiting until it can grab it
20. In a modern operating system a process is able to acquire more than one lock at a time.
	1. true but they must be in the same order acrsoss allt threads to avoid deadlock
21. In a modern operating system Spinlocks are better than Binary Semaphores (aka Mutex) because the Operating System can force the holder of a spinlock to release the lock.
22. In a modern operating system Spinlocks are better than Binary Semaphores (aka Mutex) because the Operating System can force the holder of a spinlock to release the lock.
	1. false, [[Spinlock Disadvantages]]
23. A starvation is when a parent process exits and leaves its children processes in limbo.
	1. fals,e this is orphan process but they get reparented to the initproc
24. Because a "freed" spinlock contains the value 0 it is actually okay to release it multiple times since it doesn't change its value.
	1. false, this can elad to reace conditions or undefined behavior